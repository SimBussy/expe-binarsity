{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Simon/Dev/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sys import stdout, argv\n",
    "from prettytable import PrettyTable\n",
    "from time import time\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from tick.preprocessing import FeaturesBinarizer\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import pylab as pl\n",
    "import seaborn as sns\n",
    "from pygam import LogisticGAM\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.972861</td>\n",
       "      <td>0.653855</td>\n",
       "      <td>1.176225</td>\n",
       "      <td>1.157156</td>\n",
       "      <td>-1.739873</td>\n",
       "      <td>-0.874309</td>\n",
       "      <td>0.567765</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>0.810061</td>\n",
       "      <td>-0.252552</td>\n",
       "      <td>1.921887</td>\n",
       "      <td>0.889637</td>\n",
       "      <td>0.410772</td>\n",
       "      <td>1.145621</td>\n",
       "      <td>1.932632</td>\n",
       "      <td>0.994464</td>\n",
       "      <td>1.367815</td>\n",
       "      <td>0.040714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.444840</td>\n",
       "      <td>-0.134298</td>\n",
       "      <td>-0.709972</td>\n",
       "      <td>0.451719</td>\n",
       "      <td>-1.613871</td>\n",
       "      <td>-0.768661</td>\n",
       "      <td>1.219918</td>\n",
       "      <td>0.504026</td>\n",
       "      <td>1.831248</td>\n",
       "      <td>-0.431385</td>\n",
       "      <td>0.526283</td>\n",
       "      <td>0.941514</td>\n",
       "      <td>1.587535</td>\n",
       "      <td>2.024308</td>\n",
       "      <td>0.603498</td>\n",
       "      <td>1.562374</td>\n",
       "      <td>1.135454</td>\n",
       "      <td>0.180910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.381256</td>\n",
       "      <td>-0.976145</td>\n",
       "      <td>0.693152</td>\n",
       "      <td>0.448959</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>-0.677328</td>\n",
       "      <td>2.033060</td>\n",
       "      <td>1.533041</td>\n",
       "      <td>3.046260</td>\n",
       "      <td>-1.005285</td>\n",
       "      <td>0.569386</td>\n",
       "      <td>1.015211</td>\n",
       "      <td>1.582217</td>\n",
       "      <td>1.551914</td>\n",
       "      <td>0.761215</td>\n",
       "      <td>1.715464</td>\n",
       "      <td>1.492257</td>\n",
       "      <td>0.090719</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.456398</td>\n",
       "      <td>1.099371</td>\n",
       "      <td>1.512453</td>\n",
       "      <td>0.751772</td>\n",
       "      <td>0.638967</td>\n",
       "      <td>-0.742216</td>\n",
       "      <td>0.322601</td>\n",
       "      <td>1.321054</td>\n",
       "      <td>0.169502</td>\n",
       "      <td>0.359941</td>\n",
       "      <td>0.489256</td>\n",
       "      <td>0.416168</td>\n",
       "      <td>0.754829</td>\n",
       "      <td>0.303750</td>\n",
       "      <td>0.461067</td>\n",
       "      <td>0.345541</td>\n",
       "      <td>0.733242</td>\n",
       "      <td>0.186044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.437818</td>\n",
       "      <td>-1.119883</td>\n",
       "      <td>-1.336823</td>\n",
       "      <td>0.502320</td>\n",
       "      <td>-1.717515</td>\n",
       "      <td>1.017067</td>\n",
       "      <td>0.215619</td>\n",
       "      <td>-0.461200</td>\n",
       "      <td>0.323671</td>\n",
       "      <td>0.173626</td>\n",
       "      <td>0.411898</td>\n",
       "      <td>0.370525</td>\n",
       "      <td>0.798260</td>\n",
       "      <td>0.671369</td>\n",
       "      <td>0.385910</td>\n",
       "      <td>0.515522</td>\n",
       "      <td>0.479110</td>\n",
       "      <td>0.029058</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.972861  0.653855  1.176225  1.157156 -1.739873 -0.874309  0.567765   \n",
       "1  0.444840 -0.134298 -0.709972  0.451719 -1.613871 -0.768661  1.219918   \n",
       "2  0.381256 -0.976145  0.693152  0.448959  0.891753 -0.677328  2.033060   \n",
       "3  0.456398  1.099371  1.512453  0.751772  0.638967 -0.742216  0.322601   \n",
       "4  0.437818 -1.119883 -1.336823  0.502320 -1.717515  1.017067  0.215619   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0 -0.175000  0.810061 -0.252552  1.921887  0.889637  0.410772  1.145621   \n",
       "1  0.504026  1.831248 -0.431385  0.526283  0.941514  1.587535  2.024308   \n",
       "2  1.533041  3.046260 -1.005285  0.569386  1.015211  1.582217  1.551914   \n",
       "3  1.321054  0.169502  0.359941  0.489256  0.416168  0.754829  0.303750   \n",
       "4 -0.461200  0.323671  0.173626  0.411898  0.370525  0.798260  0.671369   \n",
       "\n",
       "         14        15        16        17  18  \n",
       "0  1.932632  0.994464  1.367815  0.040714   0  \n",
       "1  0.603498  1.562374  1.135454  0.180910   1  \n",
       "2  0.761215  1.715464  1.492257  0.090719   1  \n",
       "3  0.461067  0.345541  0.733242  0.186044   0  \n",
       "4  0.385910  0.515522  0.479110  0.029058   0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'susy'\n",
    "test = False\n",
    "header = None # None \"infer\"\n",
    "directory = 'results'\n",
    "os.chdir('./datasets/%s' % filename)\n",
    "df = pd.read_csv('./%s' % filename, header=header)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop lines with NaN values\n",
    "df.dropna(axis=0, how='any', inplace=True)\n",
    "\n",
    "# if dataset churn: drop phone feature\n",
    "if filename == 'churn':\n",
    "    df = df.drop(df.columns[[3]], axis=1)\n",
    "\n",
    "# get label (have to be the last column!)\n",
    "idx_label_column = -1\n",
    "labels = df.iloc[:, idx_label_column]\n",
    "labels = (labels.values != labels.values[0]).astype(int)\n",
    "\n",
    "# drop it from df\n",
    "df = df.drop(df.columns[[idx_label_column]], axis=1)\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X, X_test, y, y_test = train_test_split(\n",
    "    df, labels, test_size=.33, random_state=0, stratify=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:\n",
      "(2638545, 18)\n",
      "Test:\n",
      "(1299582, 18)\n",
      "data centered and reduced\n"
     ]
    }
   ],
   "source": [
    "if test:\n",
    "    n_restrict = 200\n",
    "    X = X.iloc[:n_restrict, :]\n",
    "    y = y[:n_restrict]\n",
    "    X_test = X_test.iloc[:n_restrict, :]\n",
    "    y_test = y_test[:n_restrict]\n",
    "\n",
    "# get categorical features index\n",
    "cate_feat_idx = []\n",
    "for i in range(X.shape[1]):\n",
    "    feature_type = FeaturesBinarizer._detect_feature_type(X.ix[:, i])\n",
    "    if feature_type == 'discrete':\n",
    "        cate_feat_idx.append(i)\n",
    "\n",
    "original_feature_names = X.columns\n",
    "\n",
    "feature_names_cont = list()\n",
    "for i, name in enumerate(original_feature_names):\n",
    "    if i not in cate_feat_idx:\n",
    "        feature_names_cont.append(name)\n",
    "\n",
    "# separate continuous and categorical features\n",
    "X_cat = X[X.columns[cate_feat_idx]]\n",
    "X_test_cat = X_test[X_test.columns[cate_feat_idx]]\n",
    "X_cat.reset_index(drop=True, inplace=True)\n",
    "X_test_cat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "X_cont = X.drop(X.columns[cate_feat_idx], axis=1)\n",
    "X_test_cont = X_test.drop(X_test.columns[cate_feat_idx], axis=1)\n",
    "X_cont.reset_index(drop=True, inplace=True)\n",
    "X_test_cont.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"Training:\")\n",
    "print(X.shape)\n",
    "print(\"Test:\")\n",
    "print(X_test.shape)\n",
    "\n",
    "# Center and reduce continuous data\n",
    "standardscaler = StandardScaler()\n",
    "X_std = pd.DataFrame(standardscaler.fit_transform(X_cont))\n",
    "X_test_std = pd.DataFrame(standardscaler.transform(X_test_cont))\n",
    "print(\"data centered and reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Simon/Dev/anaconda/lib/python3.6/site-packages/pygam/pygam.py:823: VisibleDeprecationWarning: using a boolean instead of an integer will result in an error in the future\n",
      "  coef = coef[fit_linear:]\n",
      "/Users/Simon/Dev/anaconda/lib/python3.6/site-packages/pygam/utils.py:68: UserWarning: Could not import Scikit-Sparse or Suite-Sparse.\n",
      "This will slow down optimization for models with monotonicity/convexity penalties and many splines.\n",
      "See installation instructions for installing Scikit-Sparse and Suite-Sparse via Conda.\n",
      "  warnings.warn(msg)\n",
      "/Users/Simon/Dev/anaconda/lib/python3.6/site-packages/pygam/links.py:149: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return dist.levels/(mu*(dist.levels - mu))\n",
      "/Users/Simon/Dev/anaconda/lib/python3.6/site-packages/pygam/pygam.py:888: RuntimeWarning: invalid value encountered in multiply\n",
      "  return sp.sparse.diags((self.link.gradient(mu, self.distribution)**2 * self.distribution.V(mu=mu))**-0.5)\n",
      "/Users/Simon/Dev/anaconda/lib/python3.6/site-packages/pygam/pygam.py:907: RuntimeWarning: invalid value encountered in greater_equal\n",
      "  mask = (np.abs(weights) >= np.sqrt(EPS)) * (weights != np.nan)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+--------+\n",
      "| Algos |   AUC    |  time  |\n",
      "+-------+----------+--------+\n",
      "|  GAM  | 0.856431 | 42.543 |\n",
      "+-------+----------+--------+\n"
     ]
    }
   ],
   "source": [
    "model = \"GAM\"\n",
    "lam = 4\n",
    "n_splines=5\n",
    "n_restrict = 300000\n",
    "\n",
    "t = PrettyTable(['Algos', 'AUC', 'time'])\n",
    "best_params = np.load('./%s/learning_curves/best_params_%s.npy' % (directory, model)).item()\n",
    "best_params['lam'] = lam\n",
    "best_params['n_splines'] = n_splines\n",
    "np.save('./results/learning_curves/best_params_%s.npy' % model, best_params)\n",
    "\n",
    "start = time()\n",
    "gam = LogisticGAM(dtype='numerical', lam=lam, n_splines=n_splines)\n",
    "gam.fit(X_std.iloc[:n_restrict, :], y[:n_restrict])\n",
    "y_pred = gam.predict_proba(X_test_std)\n",
    "np.save('./results/y_pred/9-%s' % model, y_pred)\n",
    "np.save('./results/y_test', y_test)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "auc = max(auc, 1 - auc)\n",
    "\n",
    "t.add_row([\"GAM\", \"%g\" % auc, \"%.3f\" % (time() - start)])\n",
    "\n",
    "# Final performances comparison\n",
    "print(t)\n",
    "results = open(\"./results/results.txt\", \"w\")\n",
    "results.write('%s' % t)\n",
    "results.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
